# config/maestrocat_macos.yaml
# MaestroCat Configuration for macOS (Apple Silicon)
# Uses native macOS services instead of Docker containers

vad:
  energy_threshold: 0.5
  min_speech_ms: 250
  pause_ms: 800

# WhisperLive STT (Docker, CPU-optimized for macOS)
stt:
  service: "whisperlive"  # Uses Docker WhisperLive service
  host: "localhost"
  port: 9090
  model_size: "medium"    # Options: "tiny", "small", "medium", "large"
  language: "en"          # Language code or "auto" for detection
  translate: false  
  sample_rate: 16000

# Docker Ollama LLM (CPU-optimized for macOS consistency)
llm:
  base_url: "http://localhost:11434"  # Docker Ollama service
  model: "llama3.2:3b"               # Recommended model
  temperature: 0.7
  max_tokens: 1000
  top_p: 0.9
  top_k: 40
  system_prompt: "You are MaestroCat, a helpful AI voice assistant. Keep responses concise and conversational. If interrupted, acknowledge it naturally."

# Kokoro TTS (Docker) - preferred for streaming
tts:
  service: "kokoro"      # Options: "macos", "pyttsx3", "kokoro"
  base_url: "http://localhost:5001"
  voice: "af_bella"      # Kokoro voice options
  speed: 1.0
  sample_rate: 24000     # Kokoro's native sample rate

# Alternative TTS configurations
tts_alternatives:
  # macOS System TTS with different voice
  alex:
    service: "macos"
    voice: "Alex"
    rate: 180
    volume: 0.9
    sample_rate: 22050
    
  # PyTTSx3 TTS (requires: pip install pyttsx3 pyobjc)
  pyttsx3:
    service: "pyttsx3"
    voice_id: null         # Use default voice
    rate: 200
    volume: 0.8
    sample_rate: 22050
    
  # Kokoro TTS (if Docker is available)
  kokoro:
    service: "kokoro"
    base_url: "http://localhost:5001"
    voice: "af_bella"
    speed: 1.0
    sample_rate: 24000

interruption:
  threshold: 0.2
  ack_delay: 0.05

modules:
  voice_recognition:
    enabled: false
    model: "speechbrain/spkrec-ecapa-voxceleb"
  memory:
    enabled: false
    max_history: 100

# macOS-specific settings
macos:
  # Audio settings
  audio:
    input_device: null     # null = use default microphone
    output_device: null    # null = use default speakers
    buffer_size: 1024      # Audio buffer size
    
  # Performance settings for Apple Silicon
  performance:
    mlx_whisper: true      # Use MLX acceleration for Whisper
    ollama_threads: 0      # 0 = auto-detect cores
    metal_acceleration: true  # Use Metal GPU acceleration where available
    
  # Service installation hints
  dependencies:
    mlx_whisper: "pip install 'pipecat-ai[mlx-whisper]'"
    ollama: "brew install ollama"
    ffmpeg: "brew install ffmpeg"  # Optional for audio processing
    
# Development settings
development:
  log_level: "INFO"
  debug_ui: true
  debug_port: 8080
  websocket_port: 8765
  
# Production optimizations for Apple Silicon
production:
  # Smaller models for better performance
  stt:
    model_size: "tiny"     # Fastest Whisper model
    
  llm:
    model: "llama3.2:1b"   # Smaller, faster model
    
  # Optimized for real-time performance
  audio:
    buffer_size: 512       # Smaller buffer for lower latency
    
  performance:
    mlx_optimization: true  # Enable MLX optimizations for better performance